using Amazon.S3;
using Amazon.S3.Model;
using System;
using System.Collections.Generic;
using System.IO;
using System.Text;
using System.Threading.Tasks;

public class S3ZipUploader
{
    private const int ChunkSize = 5 * 1024 * 1024; // S3 minimum part size

    public async Task StreamZipToS3Async(List<(string FileName, byte[] FileContent)> files, string bucketName, string keyName)
    {
        using var s3Client = new AmazonS3Client();
        var initiateRequest = new InitiateMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = keyName
        };

        var initiateResponse = await s3Client.InitiateMultipartUploadAsync(initiateRequest);
        var partETags = new List<PartETag>();
        int partNumber = 1;

        var centralDirectory = new List<byte[]>();
        long totalBytesWritten = 0;

        try
        {
            using var uploadStream = new MemoryStream(); // Buffer for multipart uploads
            foreach (var (fileName, fileContent) in files)
            {
                uint crc32 = CalculateCrc32(fileContent);

                // Write Local File Header
                var localFileHeader = CreateLocalFileHeader(fileName, fileContent.Length, crc32);
                uploadStream.Write(localFileHeader, 0, localFileHeader.Length);

                // Write File Content
                uploadStream.Write(fileContent, 0, fileContent.Length);

                // Add to Central Directory
                var centralDirectoryEntry = CreateCentralDirectoryEntry(fileName, fileContent.Length, crc32, totalBytesWritten);
                centralDirectory.Add(centralDirectoryEntry);

                totalBytesWritten += localFileHeader.Length + fileContent.Length;

                // Upload chunk if necessary
                if (uploadStream.Length >= ChunkSize)
                {
                    await UploadChunkAsync(s3Client, initiateResponse, uploadStream, partETags, partNumber++);
                }
            }

            // Write Central Directory and End of Central Directory Record
            var centralDirectoryBytes = CombineCentralDirectory(centralDirectory, totalBytesWritten);
            uploadStream.Write(centralDirectoryBytes, 0, centralDirectoryBytes.Length);

            if (uploadStream.Length > 0)
            {
                await UploadChunkAsync(s3Client, initiateResponse, uploadStream, partETags, partNumber++);
            }
        }
        catch
        {
            // Abort multipart upload on error
            var abortRequest = new AbortMultipartUploadRequest
            {
                BucketName = bucketName,
                Key = keyName,
                UploadId = initiateResponse.UploadId
            };
            await s3Client.AbortMultipartUploadAsync(abortRequest);
            throw;
        }

        // Complete the multipart upload
        var completeRequest = new CompleteMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = keyName,
            UploadId = initiateResponse.UploadId,
            PartETags = partETags
        };
        await s3Client.CompleteMultipartUploadAsync(completeRequest);
    }

    private async Task UploadChunkAsync(IAmazonS3 s3Client, InitiateMultipartUploadResponse initiateResponse, MemoryStream uploadStream, List<PartETag> partETags, int partNumber)
    {
        uploadStream.Position = 0;

        var uploadPartRequest = new UploadPartRequest
        {
            BucketName = initiateResponse.BucketName,
            Key = initiateResponse.Key,
            UploadId = initiateResponse.UploadId,
            PartNumber = partNumber,
            InputStream = uploadStream,
            PartSize = uploadStream.Length
        };

        var uploadPartResponse = await s3Client.UploadPartAsync(uploadPartRequest);
        partETags.Add(new PartETag(uploadPartResponse.PartNumber, uploadPartResponse.ETag));

        uploadStream.SetLength(0); // Clear the buffer for the next part
    }

    private uint CalculateCrc32(byte[] data)
    {
        using var crc32 = new System.IO.Hashing.Crc32();
        crc32.Append(data);
        return BitConverter.ToUInt32(crc32.GetCurrentHash(), 0);
    }

    private byte[] CreateLocalFileHeader(string fileName, int fileSize, uint crc32)
    {
        using var headerStream = new MemoryStream();
        using var writer = new BinaryWriter(headerStream);

        writer.Write(0x04034b50); // Local file header signature
        writer.Write((short)20); // Version needed to extract
        writer.Write((short)0); // General purpose bit flag
        writer.Write((short)0); // Compression method (0 = store, no compression)
        writer.Write((int)DateTimeToDosTime(DateTime.Now)); // File last modification time
        writer.Write(crc32); // CRC-32
        writer.Write(fileSize); // Compressed size
        writer.Write(fileSize); // Uncompressed size
        writer.Write((short)fileName.Length); // File name length
        writer.Write((short)0); // Extra field length

        writer.Write(Encoding.UTF8.GetBytes(fileName)); // File name

        return headerStream.ToArray();
    }

    private byte[] CreateCentralDirectoryEntry(string fileName, int fileSize, uint crc32, long offset)
    {
        using var directoryStream = new MemoryStream();
        using var writer = new BinaryWriter(directoryStream);

        writer.Write(0x02014b50); // Central directory file header signature
        writer.Write((short)20); // Version made by
        writer.Write((short)20); // Version needed to extract
        writer.Write((short)0); // General purpose bit flag
        writer.Write((short)0); // Compression method
        writer.Write((int)DateTimeToDosTime(DateTime.Now)); // File last modification time
        writer.Write(crc32); // CRC-32
        writer.Write(fileSize); // Compressed size
        writer.Write(fileSize); // Uncompressed size
        writer.Write((short)fileName.Length); // File name length
        writer.Write((short)0); // Extra field length
        writer.Write((short)0); // File comment length
        writer.Write((short)0); // Disk number start
        writer.Write((short)0); // Internal file attributes
        writer.Write(0); // External file attributes
        writer.Write((int)offset); // Relative offset of local file header

        writer.Write(Encoding.UTF8.GetBytes(fileName)); // File name

        return directoryStream.ToArray();
    }

    private byte[] CombineCentralDirectory(List<byte[]> centralDirectoryEntries, long centralDirectoryOffset)
    {
        using var centralStream = new MemoryStream();
        foreach (var entry in centralDirectoryEntries)
        {
            centralStream.Write(entry, 0, entry.Length);
        }

        // Write end of central directory record
        using var writer = new BinaryWriter(centralStream);
        writer.Write(0x06054b50); // End of central directory signature
        writer.Write((short)0); // Number of this disk
        writer.Write((short)0); // Disk where central directory starts
        writer.Write((short)centralDirectoryEntries.Count); // Number of central directory records on this disk
        writer.Write((short)centralDirectoryEntries.Count); // Total number of central directory records
        writer.Write((int)centralStream.Length); // Size of central directory
        writer.Write((int)centralDirectoryOffset); // Offset of start of central directory
        writer.Write((short)0); // Comment length

        return centralStream.ToArray();
    }

    private int DateTimeToDosTime(DateTime dateTime)
    {
        return ((dateTime.Year - 1980) << 25) |
               (dateTime.Month << 21) |
               (dateTime.Day << 16) |
               (dateTime.Hour << 11) |
               (dateTime.Minute << 5) |
               (dateTime.Second >> 1);
    }
}

public class S3ZipUploaderWithCompression
{
    private const int ChunkSize = 5 * 1024 * 1024; // S3 minimum part size

    public async Task StreamZipToS3Async(List<(string FileName, byte[] FileContent)> files, string bucketName, string keyName)
    {
        using var s3Client = new AmazonS3Client();
        var initiateRequest = new InitiateMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = keyName
        };

        var initiateResponse = await s3Client.InitiateMultipartUploadAsync(initiateRequest);
        var partETags = new List<PartETag>();
        int partNumber = 1;

        var centralDirectory = new List<byte[]>();
        long totalBytesWritten = 0;

        try
        {
            using var uploadStream = new MemoryStream(); // Buffer for multipart uploads
            foreach (var (fileName, fileContent) in files)
            {
                // Compress the file content
                var compressedContent = CompressData(fileContent);
                uint crc32 = CalculateCrc32(fileContent); // CRC should be calculated on uncompressed content

                // Write Local File Header
                var localFileHeader = CreateLocalFileHeader(fileName, compressedContent.Length, fileContent.Length, crc32);
                uploadStream.Write(localFileHeader, 0, localFileHeader.Length);

                // Write Compressed Content
                uploadStream.Write(compressedContent, 0, compressedContent.Length);

                // Add to Central Directory
                var centralDirectoryEntry = CreateCentralDirectoryEntry(fileName, compressedContent.Length, fileContent.Length, crc32, totalBytesWritten);
                centralDirectory.Add(centralDirectoryEntry);

                totalBytesWritten += localFileHeader.Length + compressedContent.Length;

                // Upload chunk if necessary
                if (uploadStream.Length >= ChunkSize)
                {
                    await UploadChunkAsync(s3Client, initiateResponse, uploadStream, partETags, partNumber++);
                }
            }

            // Write Central Directory and End of Central Directory Record
            var centralDirectoryBytes = CombineCentralDirectory(centralDirectory, totalBytesWritten);
            uploadStream.Write(centralDirectoryBytes, 0, centralDirectoryBytes.Length);

            if (uploadStream.Length > 0)
            {
                await UploadChunkAsync(s3Client, initiateResponse, uploadStream, partETags, partNumber++);
            }
        }
        catch
        {
            // Abort multipart upload on error
            var abortRequest = new AbortMultipartUploadRequest
            {
                BucketName = bucketName,
                Key = keyName,
                UploadId = initiateResponse.UploadId
            };
            await s3Client.AbortMultipartUploadAsync(abortRequest);
            throw;
        }

        // Complete the multipart upload
        var completeRequest = new CompleteMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = keyName,
            UploadId = initiateResponse.UploadId,
            PartETags = partETags
        };
        await s3Client.CompleteMultipartUploadAsync(completeRequest);
    }

    private async Task UploadChunkAsync(IAmazonS3 s3Client, InitiateMultipartUploadResponse initiateResponse, MemoryStream uploadStream, List<PartETag> partETags, int partNumber)
    {
        uploadStream.Position = 0;

        var uploadPartRequest = new UploadPartRequest
        {
            BucketName = initiateResponse.BucketName,
            Key = initiateResponse.Key,
            UploadId = initiateResponse.UploadId,
            PartNumber = partNumber,
            InputStream = uploadStream,
            PartSize = uploadStream.Length
        };

        var uploadPartResponse = await s3Client.UploadPartAsync(uploadPartRequest);
        partETags.Add(new PartETag(uploadPartResponse.PartNumber, uploadPartResponse.ETag));

        uploadStream.SetLength(0); // Clear the buffer for the next part
    }

    private uint CalculateCrc32(byte[] data)
    {
        using var crc32 = new System.IO.Hashing.Crc32();
        crc32.Append(data);
        return BitConverter.ToUInt32(crc32.GetCurrentHash(), 0);
    }

    private byte[] CompressData(byte[] data)
    {
        using var compressedStream = new MemoryStream();
        using (var deflateStream = new System.IO.Compression.DeflateStream(compressedStream, System.IO.Compression.CompressionLevel.Optimal))
        {
            deflateStream.Write(data, 0, data.Length);
        }
        return compressedStream.ToArray();
    }

    private byte[] CreateLocalFileHeader(string fileName, int compressedSize, int uncompressedSize, uint crc32)
    {
        using var headerStream = new MemoryStream();
        using var writer = new BinaryWriter(headerStream);

        writer.Write(0x04034b50); // Local file header signature
        writer.Write((short)20); // Version needed to extract
        writer.Write((short)0); // General purpose bit flag
        writer.Write((short)8); // Compression method (8 = Deflate)
        writer.Write((int)DateTimeToDosTime(DateTime.Now)); // File last modification time
        writer.Write(crc32); // CRC-32
        writer.Write(compressedSize); // Compressed size
        writer.Write(uncompressedSize); // Uncompressed size
        writer.Write((short)fileName.Length); // File name length
        writer.Write((short)0); // Extra field length

        writer.Write(Encoding.UTF8.GetBytes(fileName)); // File name

        return headerStream.ToArray();
    }

    private byte[] CreateCentralDirectoryEntry(string fileName, int compressedSize, int uncompressedSize, uint crc32, long offset)
    {
        using var directoryStream = new MemoryStream();
        using var writer = new BinaryWriter(directoryStream);

        writer.Write(0x02014b50); // Central directory file header signature
        writer.Write((short)20); // Version made by
        writer.Write((short)20); // Version needed to extract
        writer.Write((short)0); // General purpose bit flag
        writer.Write((short)8); // Compression method (8 = Deflate)
        writer.Write((int)DateTimeToDosTime(DateTime.Now)); // File last modification time
        writer.Write(crc32); // CRC-32
        writer.Write(compressedSize); // Compressed size
        writer.Write(uncompressedSize); // Uncompressed size
        writer.Write((short)fileName.Length); // File name length
        writer.Write((short)0); // Extra field length
        writer.Write((short)0); // File comment length
        writer.Write((short)0); // Disk number start
        writer.Write((short)0); // Internal file attributes
        writer.Write(0); // External file attributes
        writer.Write((int)offset); // Relative offset of local file header

        writer.Write(Encoding.UTF8.GetBytes(fileName)); // File name

        return directoryStream.ToArray();
    }

    private byte[] CombineCentralDirectory(List<byte[]> centralDirectoryEntries, long centralDirectoryOffset)
    {
        using var centralStream = new MemoryStream();
        foreach (var entry in centralDirectoryEntries)
        {
            centralStream.Write(entry, 0, entry.Length);
        }

        using var writer = new BinaryWriter(centralStream);
        writer.Write(0x06054b50); // End of central directory signature
        writer.Write((short)0); // Number of this disk
        writer.Write((short)0); // Disk where central directory starts
        writer.Write((short)centralDirectoryEntries.Count); // Number of central directory records on this disk
        writer.Write((short)centralDirectoryEntries.Count); // Total number of central directory records
        writer.Write((int)centralStream.Length); // Size of central directory
        writer.Write((int)centralDirectoryOffset); // Offset of start of central directory
        writer.Write((short)0); // Comment length

        return centralStream.ToArray();
    }

    private int DateTimeToDosTime(DateTime dateTime)
    {
        return ((dateTime.Year - 1980) << 25) |
               (dateTime.Month << 21) |
               (dateTime.Day << 16) |
               (dateTime.Hour << 11) |
               (dateTime.Minute << 5) |
               (dateTime.Second >> 1);
    }
}

public class S3JsonMultipartUploader
{
    private const int ChunkSize = 5 * 1024 * 1024; // 5 MB

    public async Task UploadLargeJsonObjectAsync<T>(T largeObject, string bucketName, string keyName)
    {
        using var s3Client = new AmazonS3Client();
        var initiateRequest = new InitiateMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = keyName
        };

        var initiateResponse = await s3Client.InitiateMultipartUploadAsync(initiateRequest);
        var partETags = new List<PartETag>();
        int partNumber = 1;

        try
        {
            using var memoryStream = new MemoryStream();
            using var gzipStream = new GZipStream(memoryStream, CompressionLevel.Optimal, leaveOpen: true);
            using var writer = new Utf8JsonWriter(gzipStream, new JsonWriterOptions { Indented = false });

            writer.WriteStartObject();

            // Incrementally serialize and upload JSON properties
            var properties = typeof(T).GetProperties();
            foreach (var property in properties)
            {
                var value = property.GetValue(largeObject);
                if (value is IEnumerable<object> enumerable)
                {
                    writer.WritePropertyName(property.Name);
                    writer.WriteStartArray();

                    foreach (var item in enumerable)
                    {
                        JsonSerializer.Serialize(writer, item);

                        // Check if the buffer size exceeds the chunk size
                        if (memoryStream.Length >= ChunkSize)
                        {
                            await UploadChunkAsync(s3Client, initiateResponse, memoryStream, partETags, partNumber++);
                        }
                    }

                    writer.WriteEndArray();
                }
                else
                {
                    writer.WritePropertyName(property.Name);
                    JsonSerializer.Serialize(writer, value);

                    // Check if the buffer size exceeds the chunk size
                    if (memoryStream.Length >= ChunkSize)
                    {
                        await UploadChunkAsync(s3Client, initiateResponse, memoryStream, partETags, partNumber++);
                    }
                }
            }

            writer.WriteEndObject();
            await writer.FlushAsync();

            // Ensure the final chunk is uploaded
            if (memoryStream.Length > 0)
            {
                await UploadChunkAsync(s3Client, initiateResponse, memoryStream, partETags, partNumber++);
            }
        }
        catch
        {
            // Abort multipart upload on error
            var abortRequest = new AbortMultipartUploadRequest
            {
                BucketName = bucketName,
                Key = keyName,
                UploadId = initiateResponse.UploadId
            };
            await s3Client.AbortMultipartUploadAsync(abortRequest);
            throw;
        }

        // Complete the multipart upload
        var completeRequest = new CompleteMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = keyName,
            UploadId = initiateResponse.UploadId,
            PartETags = partETags
        };
        await s3Client.CompleteMultipartUploadAsync(completeRequest);
    }

    private async Task UploadChunkAsync(IAmazonS3 s3Client, InitiateMultipartUploadResponse initiateResponse, MemoryStream memoryStream, List<PartETag> partETags, int partNumber)
    {
        memoryStream.Position = 0;

        var uploadPartRequest = new UploadPartRequest
        {
            BucketName = initiateResponse.BucketName,
            Key = initiateResponse.Key,
            UploadId = initiateResponse.UploadId,
            PartNumber = partNumber,
            PartSize = memoryStream.Length,
            InputStream = memoryStream
        };

        var uploadPartResponse = await s3Client.UploadPartAsync(uploadPartRequest);
        partETags.Add(new PartETag(partNumber, uploadPartResponse.ETag));

        // Clear the memory stream
        memoryStream.SetLength(0);
    }
}

public class S3JsonUploader
{
    private readonly IAmazonS3 _s3Client;
    private const int MultipartChunkSize = 5 * 1024 * 1024; // 5 MB

    public S3JsonUploader(IAmazonS3 s3Client)
    {
        _s3Client = s3Client;
    }

    public async Task UploadJsonAsZip(string bucketName, string key, object jsonObject)
    {
        var initRequest = new InitiateMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = key
        };
        var initResponse = await _s3Client.InitiateMultipartUploadAsync(initRequest);

        try
        {
            using var memoryStream = new MemoryStream();
            using var zipStream = new MemoryStream();

            var centralDirectoryOffset = memoryStream.Position;
            var centralDirectory = new MemoryStream();

            // 1. Write Local File Header
            string fileName = "data.json";
            var fileHeader = CreateLocalFileHeader(fileName);
            await memoryStream.WriteAsync(fileHeader, 0, fileHeader.Length);

            // 2. Write Compressed JSON Data
            using (var deflateStream = new DeflateStream(memoryStream, CompressionLevel.Optimal, leaveOpen: true))
            {
                var json = System.Text.Json.JsonSerializer.Serialize(jsonObject);
                var jsonData = Encoding.UTF8.GetBytes(json);
                await deflateStream.WriteAsync(jsonData, 0, jsonData.Length);
            }

            // Calculate compressed size
            var compressedSize = memoryStream.Position - centralDirectoryOffset;

            // 3. Write Central Directory Entry
            var centralDirectoryEntry = CreateCentralDirectoryEntry(fileName, centralDirectoryOffset, compressedSize, json.Length);
            await centralDirectory.WriteAsync(centralDirectoryEntry, 0, centralDirectoryEntry.Length);

            // 4. Write End of Central Directory
            var endOfCentralDirectory = CreateEndOfCentralDirectory(1, centralDirectoryOffset, centralDirectory.Length);
            await zipStream.WriteAsync(centralDirectory.ToArray());
            await zipStream.WriteAsync(endOfCentralDirectory, 0, endOfCentralDirectory.Length);

            // Upload to S3 in parts
            var partNumber = 1;
            var buffer = new byte[MultipartChunkSize];
            int bytesRead;
            memoryStream.Seek(0, SeekOrigin.Begin);
            while ((bytesRead = await memoryStream.ReadAsync(buffer, 0, MultipartChunkSize)) > 0)
            {
                var uploadPartRequest = new UploadPartRequest
                {
                    BucketName = bucketName,
                    Key = key,
                    UploadId = initResponse.UploadId,
                    PartNumber = partNumber++,
                    InputStream = new MemoryStream(buffer, 0, bytesRead)
                };
                await _s3Client.UploadPartAsync(uploadPartRequest);
            }

            // Complete Multipart Upload
            var completeRequest = new CompleteMultipartUploadRequest
            {
                BucketName = bucketName,
                Key = key,
                UploadId = initResponse.UploadId
            };
            await _s3Client.CompleteMultipartUploadAsync(completeRequest);
        }
        catch (Exception)
        {
            await _s3Client.AbortMultipartUploadAsync(new AbortMultipartUploadRequest
            {
                BucketName = bucketName,
                Key = key,
                UploadId = initResponse.UploadId
            });
            throw;
        }
    }

    private byte[] CreateLocalFileHeader(string fileName)
    {
        var fileNameBytes = Encoding.UTF8.GetBytes(fileName);
        var header = new byte[30 + fileNameBytes.Length];

        // Local file header signature
        Array.Copy(BitConverter.GetBytes(0x04034b50), 0, header, 0, 4);

        // Version needed to extract
        Array.Copy(BitConverter.GetBytes((ushort)20), 0, header, 4, 2);

        // Compression method (8 = Deflate)
        Array.Copy(BitConverter.GetBytes((ushort)8), 0, header, 8, 2);

        // File name length
        Array.Copy(BitConverter.GetBytes((ushort)fileNameBytes.Length), 0, header, 26, 2);

        // File name
        Array.Copy(fileNameBytes, 0, header, 30, fileNameBytes.Length);

        return header;
    }

    private byte[] CreateCentralDirectoryEntry(string fileName, long offset, long compressedSize, long uncompressedSize)
    {
        var fileNameBytes = Encoding.UTF8.GetBytes(fileName);
        var entry = new byte[46 + fileNameBytes.Length];

        // Central directory file header signature
        Array.Copy(BitConverter.GetBytes(0x02014b50), 0, entry, 0, 4);

        // Version made by
        Array.Copy(BitConverter.GetBytes((ushort)20), 0, entry, 4, 2);

        // Compression method (8 = Deflate)
        Array.Copy(BitConverter.GetBytes((ushort)8), 0, entry, 10, 2);

        // Compressed size
        Array.Copy(BitConverter.GetBytes((uint)compressedSize), 0, entry, 20, 4);

        // File name length
        Array.Copy(BitConverter.GetBytes((ushort)fileNameBytes.Length), 0, entry, 28, 2);

        // Relative offset of local header
        Array.Copy(BitConverter.GetBytes((uint)offset), 0, entry, 42, 4);

        // File name
        Array.Copy(fileNameBytes, 0, entry, 46, fileNameBytes.Length);

        return entry;
    }

    private byte[] CreateEndOfCentralDirectory(int fileCount, long centralDirectoryOffset, long centralDirectorySize)
    {
        var endOfCentralDir = new byte[22];

        // End of central directory signature
        Array.Copy(BitConverter.GetBytes(0x06054b50), 0, endOfCentralDir, 0, 4);

        // Total number of central directory records
        Array.Copy(BitConverter.GetBytes((ushort)fileCount), 0, endOfCentralDir, 10, 2);

        // Size of the central directory
        Array.Copy(BitConverter.GetBytes((uint)centralDirectorySize), 0, endOfCentralDir, 12, 4);

        // Offset of start of central directory
        Array.Copy(BitConverter.GetBytes((uint)centralDirectoryOffset), 0, endOfCentralDir, 16, 4);

        return endOfCentralDir;
    }
}



public class S3JsonUploader
{
    private readonly IAmazonS3 _s3Client;
    private const int MultipartChunkSize = 5 * 1024 * 1024; // 5 MB

    public S3JsonUploader(IAmazonS3 s3Client)
    {
        _s3Client = s3Client;
    }

    public async Task UploadJsonAsZip(string bucketName, string key, object jsonObject)
    {
        var initRequest = new InitiateMultipartUploadRequest
        {
            BucketName = bucketName,
            Key = key
        };
        var initResponse = await _s3Client.InitiateMultipartUploadAsync(initRequest);

        try
        {
            using var memoryStream = new MemoryStream();
            using var zipStream = new MemoryStream();

            var centralDirectoryOffset = memoryStream.Position;
            var centralDirectory = new MemoryStream();

            // 1. Write Local File Header
            string fileName = "data.json";
            var fileHeader = CreateLocalFileHeader(fileName);
            await memoryStream.WriteAsync(fileHeader, 0, fileHeader.Length);

            // 2. Write Compressed JSON Data
            using (var deflateStream = new DeflateStream(memoryStream, CompressionLevel.Optimal, leaveOpen: true))
            {
                var json = System.Text.Json.JsonSerializer.Serialize(jsonObject);
                var jsonData = Encoding.UTF8.GetBytes(json);
                await deflateStream.WriteAsync(jsonData, 0, jsonData.Length);
            }

            // Calculate compressed size
            var compressedSize = memoryStream.Position - centralDirectoryOffset;

            // 3. Write Central Directory Entry
            var centralDirectoryEntry = CreateCentralDirectoryEntry(fileName, centralDirectoryOffset, compressedSize, json.Length);
            await centralDirectory.WriteAsync(centralDirectoryEntry, 0, centralDirectoryEntry.Length);

            // 4. Write End of Central Directory
            var endOfCentralDirectory = CreateEndOfCentralDirectory(1, centralDirectoryOffset, centralDirectory.Length);
            await zipStream.WriteAsync(centralDirectory.ToArray());
            await zipStream.WriteAsync(endOfCentralDirectory, 0, endOfCentralDirectory.Length);

            // Upload to S3 in parts
            var partNumber = 1;
            var buffer = new byte[MultipartChunkSize];
            int bytesRead;
            memoryStream.Seek(0, SeekOrigin.Begin);
            while ((bytesRead = await memoryStream.ReadAsync(buffer, 0, MultipartChunkSize)) > 0)
            {
                var uploadPartRequest = new UploadPartRequest
                {
                    BucketName = bucketName,
                    Key = key,
                    UploadId = initResponse.UploadId,
                    PartNumber = partNumber++,
                    InputStream = new MemoryStream(buffer, 0, bytesRead)
                };
                await _s3Client.UploadPartAsync(uploadPartRequest);
            }

            // Complete Multipart Upload
            var completeRequest = new CompleteMultipartUploadRequest
            {
                BucketName = bucketName,
                Key = key,
                UploadId = initResponse.UploadId
            };
            await _s3Client.CompleteMultipartUploadAsync(completeRequest);
        }
        catch (Exception)
        {
            await _s3Client.AbortMultipartUploadAsync(new AbortMultipartUploadRequest
            {
                BucketName = bucketName,
                Key = key,
                UploadId = initResponse.UploadId
            });
            throw;
        }
    }

    private byte[] CreateLocalFileHeader(string fileName)
    {
        var fileNameBytes = Encoding.UTF8.GetBytes(fileName);
        var header = new byte[30 + fileNameBytes.Length];

        // Local file header signature
        Array.Copy(BitConverter.GetBytes(0x04034b50), 0, header, 0, 4);

        // Version needed to extract
        Array.Copy(BitConverter.GetBytes((ushort)20), 0, header, 4, 2);

        // Compression method (8 = Deflate)
        Array.Copy(BitConverter.GetBytes((ushort)8), 0, header, 8, 2);

        // File name length
        Array.Copy(BitConverter.GetBytes((ushort)fileNameBytes.Length), 0, header, 26, 2);

        // File name
        Array.Copy(fileNameBytes, 0, header, 30, fileNameBytes.Length);

        return header;
    }

    private byte[] CreateCentralDirectoryEntry(string fileName, long offset, long compressedSize, long uncompressedSize)
    {
        var fileNameBytes = Encoding.UTF8.GetBytes(fileName);
        var entry = new byte[46 + fileNameBytes.Length];

        // Central directory file header signature
        Array.Copy(BitConverter.GetBytes(0x02014b50), 0, entry, 0, 4);

        // Version made by
        Array.Copy(BitConverter.GetBytes((ushort)20), 0, entry, 4, 2);

        // Compression method (8 = Deflate)
        Array.Copy(BitConverter.GetBytes((ushort)8), 0, entry, 10, 2);

        // Compressed size
        Array.Copy(BitConverter.GetBytes((uint)compressedSize), 0, entry, 20, 4);

        // File name length
        Array.Copy(BitConverter.GetBytes((ushort)fileNameBytes.Length), 0, entry, 28, 2);

        // Relative offset of local header
        Array.Copy(BitConverter.GetBytes((uint)offset), 0, entry, 42, 4);

        // File name
        Array.Copy(fileNameBytes, 0, entry, 46, fileNameBytes.Length);

        return entry;
    }

    private byte[] CreateEndOfCentralDirectory(int fileCount, long centralDirectoryOffset, long centralDirectorySize)
    {
        var endOfCentralDir = new byte[22];

        // End of central directory signature
        Array.Copy(BitConverter.GetBytes(0x06054b50), 0, endOfCentralDir, 0, 4);

        // Total number of central directory records
        Array.Copy(BitConverter.GetBytes((ushort)fileCount), 0, endOfCentralDir, 10, 2);

        // Size of the central directory
        Array.Copy(BitConverter.GetBytes((uint)centralDirectorySize), 0, endOfCentralDir, 12, 4);

        // Offset of start of central directory
        Array.Copy(BitConverter.GetBytes((uint)centralDirectoryOffset), 0, endOfCentralDir, 16, 4);

        return endOfCentralDir;
    }
}
